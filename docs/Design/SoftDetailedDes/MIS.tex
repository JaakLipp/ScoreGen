\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}
\usepackage{xr}
\usepackage{hyperref}
\externaldocument{../SoftArchitecture/MG}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,    % false: boxed links; true: colored links
linkcolor=red,      % color of internal links (change box color with linkbordercolor)
citecolor=blue,     % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan       % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
2025-01-17 & 1.0 & Initial version\\
2025-03-24 & 1.1 & \href{https://github.com/emilyperica/ScoreGen/issues/208}{Updated contents of module Uses sections}  \\
2025-04-03 & 1.2 & \href{https://github.com/emilyperica/ScoreGen/issues/312}{Addressed TA feedback} \\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

\begin{itemize}
    \item \textbf{MG}: Module Guide
    \item \textbf{M1}: Hardware-Hiding Module
    \item \textbf{M2}: User Interface Module
    \item \textbf{M3}: Score Generation Module
    \item \textbf{M4}: Raw Signal Processing
    \item \textbf{M5}: Audio Feature Extraction (note, key, sig, etc.)
    \item \textbf{M6}: File Format Conversions Module
    \item \textbf{M7}: Audio Recording and Playback Module
    \item \textbf{SRS}: System Requirements Specifications
    
\end{itemize}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}
This document details the Module Interface Specifications for ScoreGen. A service
designed to transcribe user-recorded musical compositions into accurate sheet music 
by determining pitch, duration, tempo, and more advanced musical features. The service 
also aims to provide a user interface to use and interact with the product. Complementary 
documents include the SRS and MG documents. The full documentation can be found on 
\href{https://github.com/emilyperica/ScoreGen}{GitHub}.

\section{Notation}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by \progname. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
character & char & a single symbol or digit\\
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
float & $\text{Note}$ & a musical pitch, defined by a frequency in Hz\\ 
float & $\text{Duration}$ & the length of a note, measured in beats or fractions thereof\\ 
float & $\text{Rest}$ & a period of silence, defined by a duration\\ 
natural number & $\text{Tempo}$ & the speed of the music, measured in beats per minute (BPM) as a natural number\\ 
float & $\text{Dynamic}$ & the volume or intensity of a note as amplitude of a signal, e.g., piano (soft) or forte (loud)\\

\bottomrule
\end{tabular} 
\end{center}

\noindent
The specification of \progname \ uses some derived data types: sequences, strings, and
tuples. Sequences are lists filled with elements of the same data type. Strings
are sequences of characters. Tuples contain a list of values, potentially of
different types. In addition, \progname \ uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the 
\href{https://github.com/emilyperica/ScoreGen/blob/main/docs/Design/SoftArchitecture/MG.pdf}
{Module Guide} document for this project.

\begin{table}[h!]
  \centering
  \begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
  \toprule
  \textbf{Level 1} & \textbf{Level 2}\\
  \midrule

  {Hardware-Hiding Module} & -\\
  \midrule

  \multirow{3}{0.3\textwidth}{Behaviour-Hiding Module} 
  & User Interface Module \\
  & Score Generation Module \\
  & File Format Conversion Module \\
  \midrule

  \multirow{3}{0.3\textwidth}{Software Decision Module} 
  & Raw Signal Processing Module \\
  & Audio Feature Extraction Module \\
  & Audio Recording and Playback Module \\
  \bottomrule

  \end{tabular}
  \caption{Module Hierarchy}
  \label{TblMH}
\end{table}

\newpage

\section{\hyperref[mHH]{MIS of Hardware-Hiding Module}} \label{M1}

\subsection{Module}  
Hardware-Hiding Module  

\subsection{Uses}  
N/A (Hardware-Hiding Module Does not use any other modules.)

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_MICROPHONE}  
    \item \texttt{DEFAULT\_AUDIO\_OUTPUT}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{5cm}|p{2cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
initializeMicrophone & None & None & InitializationError \\  
initializeAudioOutput & None & None & InitializationError \\  
readMicrophoneBuffer & None & rawAudioData & ReadError \\  
sendToAudioOutput & audioData & None & PlaybackError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}
\begin{itemize}
    \item \textbf{microphoneState:} A state variable with domain $\{\texttt{inactive}, \texttt{active}\}$.
    \item \textbf{audioOutputState:} A state variable with domain $\{\texttt{inactive}, \texttt{active}\}$.
\end{itemize}

\subsubsection{Environment Variables}
\begin{itemize}
    \item \textbf{hardwareDriverLibrary:} The software library that provides low-level driver interfaces for the audio hardware.
    \item \textbf{deviceConfig:} A configuration structure containing parameters and settings for the audio devices.
\end{itemize}

\subsubsection{Assumptions}
\begin{enumerate}
    \item The system is equipped with functional audio input hardware (e.g., microphone) and audio output hardware (e.g., speakers or headphones).
    \item All necessary drivers are installed, properly configured, and accessible via the \texttt{hardwareDriverLibrary}.
\end{enumerate}

\subsubsection{Access Routine Semantics}

\textbf{\texttt{initializeMicrophone()}}: \\
\textbf{Precondition:} Audio input hardware is present and accessible through the \texttt{hardwareDriverLibrary}. \\
\textbf{Transition:} The state variable \texttt{microphoneState} is set to \texttt{"active"}. \\
\textbf{Postcondition:} Upon successful execution, \texttt{microphoneState} $=$ \texttt{"active"}. \\
\textbf{Exception:} Raises \texttt{InitializationError} if the audio input device fails to initialize.

\vspace{2mm}
\noindent \textbf{\texttt{sendToAudioOutput(audioData)}}: \\
\textbf{Precondition:} A valid \texttt{audioData} stream is provided, and the audio output hardware is available and operational. \\
\textbf{Transition:} The provided \texttt{audioData} is transmitted to the audio output device via the \texttt{hardwareDriverLibrary}. \\
\textbf{Postcondition:} The audio data is played through the audio output device; \texttt{audioOutputState} is updated accordingly if applicable. \\
\textbf{Exception:} Raises \texttt{PlaybackError} if the transmission or playback of the audio data fails.

\subsubsection{Local Functions}
\begin{itemize}
    \item \textbf{\texttt{detectAvailableHardware()}}: Scans and returns a list of available audio hardware devices.
    \item \textbf{\texttt{configureDeviceSettings(deviceType)}}: Retrieves and applies configuration settings specific to the provided \texttt{deviceType}.
\end{itemize}


\section{\hyperref[mUI]{MIS of User Interface Module}} \label{M2}  

\subsection{Module}  
User Interface Module  

\subsection{Uses}  
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. \\
Score Generation Module (M3): For displaying generated scores, and managine score customization settings. \\
File Format Conversions Module (M6): For importing and exporting files, and displaying PDFs. \\
Audio Recording and Playback Module (M7): For managing recoring sessions. \\

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_THEME}  
    \item \texttt{MAX\_UPLOAD\_SIZE}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{5cm}|p{2cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
displayUploadInterface & None & None & RenderError \\  
triggerPlayback & audioData & None & PlaybackError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  
\subsubsection{State Variables}
\begin{itemize}
    \item \textbf{currentScreen:} A state variable representing the active UI screen. Its domain includes possible screen identifiers (e.g., \texttt{"Home"}, \texttt{"record"}, \texttt{"View PDF"}, \texttt{"View MusicXML"}).
\end{itemize}

\subsubsection{Environment Variables}
\begin{itemize}
    \item \textbf{displayDriver:} The interface module responsible for rendering UI elements on the user's device.
    \item \textbf{inputDevices:} A collection of hardware devices (e.g., keyboard, mouse) used for user input.
\end{itemize}

\subsubsection{Assumptions}
\begin{enumerate}
    \item User devices support modern UI rendering and interactive functionalities.
    \item User device is connected to the internet for MusicXML sheet music generation.
\end{enumerate}

\subsubsection{Access Routine Semantics}

\noindent \textbf{\texttt{displayInterface()}}: \\
\textbf{Precondition:} The \texttt{displayDriver} must be available and operational. \\
\textbf{Transition:} The state variable \texttt{currentScreen} is updated to its respective view. \\
\textbf{Postcondition:} The interface is rendered on the active display screen. \\
\textbf{Exception:} Throws \texttt{RenderError} if the interface fails to render.

\vspace{2mm}
\noindent \textbf{\texttt{triggerPlayback(audioData)}}: \\
\textbf{Precondition:} Valid \texttt{audioData} must be provided, and the required audio output devices should be available. \\
\textbf{Transition:} Initiates playback of the provided \texttt{audioData}. \\
\textbf{Postcondition:} The audio data is successfully played via the corresponding output device. \\
\textbf{Exception:} Throws \texttt{PlaybackError} if audio playback fails.

\subsubsection{Local Functions}
\begin{itemize}
    \item \textbf{\texttt{processAudio(device, audioData)}}: Sends audio data to the backend from the specified \texttt{device} and returns the processed data.
    \item \textbf{\texttt{getScore(filePath)}}: Retrieves the score as a MusicXML file from the specified \texttt{filePath} and displays it in an svg format.
    \item \textbf{\texttt{validateUserInput()}}: Validates input received from the \texttt{inputDevices} and returns a status or error code based on its correctness.
    \item \textbf{\texttt{renderScreen(screenType)}}: Renders the specified screen, identified by \texttt{screenType}, using the \texttt{displayDriver}.
\end{itemize}

\section{\hyperref[mSG]{MIS of Score Generation Module}} \label{M3}  

\subsection{Module}  
Score Generation Module  

\subsection{Uses}  
Raw Signal Processing Module (M4): For receiving clean audio data. \\
Audio Feature Extraction Module (M5): For extracting musical features from audio data. (Note, Tempo, Key Signature) \\
\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_FONT\_STYLE}  
    \item \texttt{DEFAULT\_PAGE\_SIZE}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{5cm}|p{4cm}|p{2cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
generateScore & noteSequence & .mxl file & GenerationError \\  
customizeScoreSettings & settings & None & ValidationError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}
\begin{itemize}
    \item \textbf{scoreSettings:} A list defining parameters for musical score generation. Its domain includes default and user-specified settings (e.g. time signature).
\end{itemize}

\subsubsection{Environment Variables}
\begin{itemize}
    \item \textbf{fileSystemAccess:} The interface responsible for accessing the file system, enabling the reading and writing of files (including .mxl files).
\end{itemize}

\subsubsection{Assumptions}
\begin{enumerate}
    \item Input note sequences are properly formatted and adhere to the expected musical notation standards.
    \item The file system has the appropriate write permissions for saving .mxl files.
\end{enumerate}

\subsubsection{Access Routine Semantics}
\vspace{2mm}
\noindent \textbf{\texttt{generateMusicXML(noteSequence)}}: \\
\textbf{Precondition:} A valid \texttt{noteSequence} is provided, and \texttt{fileSystemAccess} is operational. \\
\textbf{Output:} An .mxl file representing the musical score corresponding to the provided \texttt{noteSequence}. \\
\textbf{Postcondition:} The generated .musicxml file is successfully stored and accessible via \texttt{fileSystemAccess}. \\
\textbf{Exception:} Throws \texttt{GenerationError} if the input \texttt{noteSequence} is invalid or if an error occurs during file creation.

\vspace{2mm}
\noindent \textbf{\texttt{customizeScoreSettings(settings)}}: \\
\textbf{Precondition:} The input \texttt{settings} adhere to the expected format for score configuration. \\
\textbf{Transition:} Updates the state variable \texttt{scoreSettings} with the new configuration values provided by \texttt{settings}. \\
\textbf{Postcondition:} The \texttt{scoreSettings} reflect the updated parameters. \\
\textbf{Exception:} Throws \texttt{ValidationError} if the provided \texttt{settings} do not meet the required validation criteria.

\subsubsection{Local Functions}
\begin{itemize}
    \item \textbf{\texttt{validateSettings(settings)}}: Checks the provided \texttt{settings} against a defined schema or set of rules, returning a validation status or error details.
    \item \textbf{\texttt{renderPDF(noteSequence, scoreSettings)}}: Generates a PDF representation of the musical score using the \texttt{noteSequence} and the current \texttt{scoreSettings}; primarily used for previewing or documentation purposes.
\end{itemize}


\section{\hyperref[mRSM]{MIS of Raw Signal Processing Module}} \label{M4}  

\subsection{Module}  
Raw Signal Processing Module  

\subsection{Uses}  
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. 

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_SAMPLING\_RATE}  
    \item \texttt{DEFAULT\_FILTER\_SETTINGS}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{4cm}|p{3cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline    
dsp & filePath & noteSequence & GenerationError \\
preprocess & rawAudioData & filteredAudioData & FilterError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}
\begin{itemize}
    \item \textbf{currentSamplingRate:} A numerical variable representing the active sampling rate (in Hz) for audio processing.
    \item \textbf{filterParameters:} A configuration object defining the parameters for the filtering operation (e.g., cutoff frequencies, filter type).
    \item \textbf{currentAudioBuffer:} A buffer that temporarily stores audio data during processing, with a defined size and format.
\end{itemize}

\subsubsection{Environment Variables}
\begin{itemize}
    \item \textbf{None.}
\end{itemize}

\subsubsection{Assumptions}
\begin{enumerate}
    \item The input audio data is provided in a readable and supported format (e.g., WAV).
\end{enumerate}

\subsubsection{Access Routine Semantics}'
\noindent \textbf{\texttt{preprocess(rawAudioData)}}: \\
\textbf{Precondition:} A valid \texttt{rawAudioData} is provided and \texttt{filterParameters} have been initialized. \\
\textbf{Output:} Returns filtered audio data with noise removed. \\
\textbf{Postcondition:} The output audio data retains the original \texttt{currentSamplingRate} while noise is reduced based on the defined \texttt{filterParameters}. \\
\textbf{Exception:} Throws \texttt{FilterError} if the filtering process fails due to invalid input or processing errors.

\subsubsection{Local Functions}
\begin{itemize}
    \item \textbf{\texttt{computeSpectralFeatures(audioData)}}: Computes and returns spectral features from the provided \texttt{audioData} for further analysis.
    \item \textbf{\texttt{hanning(audioData)}}: Applies the specified filter parameters to the audio data and returns the filtered output using a hanning window for preprocessing \cite{hanning}.
\end{itemize}


\section{\hyperref[mAFE]{MIS of Audio Feature Extraction Module}} \label{M5}  

\subsection{Module}  
Audio Feature Extraction Module  

\subsection{Uses}
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. \\
Raw Signal Processing Module (M4): For receiving filtered audio data. \\
Score Generation Module (M3): To format extracted features properly \\

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_FEATURE\_SET}  
    \item \texttt{DEFAULT\_WINDOW\_SIZE}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{4.5cm}|p{4cm}|p{2.5cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline    
dsp & filePath & featureSet & GenerationError \\
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}  
\begin{itemize}  
    \item \texttt{featureSettings}  
\end{itemize}  

\subsubsection{Environment Variables}  
\begin{itemize}  
    \item None  
\end{itemize}  

\subsubsection{Assumptions}  
\begin{itemize}  
    \item Input audio has been processed by the Raw Signal Processing Module.  
\end{itemize}  

\subsubsection{Access Routine Semantics}  
\noindent \textbf{\texttt{dsp(filePath)}}:\\
\textbf{Precondition:} Valid \texttt{filePath} is provided, and \texttt{fileSystemAccess} is operational. \\
\textbf{Output:}  \\ Audio features such as pitch, tempo, and dynamics or all notes played.
\textbf{Postcondition:} The extracted data is successfully stored and accessible via other functions. \\
\textbf{Exception:} Throws \texttt{GenerationError} if the input \texttt{noteSequence} is invalid or if an error occurs during signal processing.

\subsubsection{Local Functions}  
\begin{itemize}  
    \item \texttt{\texttt{getBPM(audioData)}}: Analyzes the audio data to determine the beats per minute (BPM) and returns the calculated tempo.
    \item \textbf{\texttt{detectPitch(audioData)}}: Analyzes the audio data to identify the pitch and returns the detected frequency or note name.
    \item \textbf{\texttt{getKeySignature(noteSequence)}}: Analyzes the note sequence to determine the key signature using the Krumhansl-Schmuckler algorithm \cite{krumhansl-schmuckler}.
    \item \textbf{\texttt{detectOnsets(audioData)}}: Identifies the onset times of notes in the audio data and returns a list of timestamps.
    
\end{itemize}  

\section{\hyperref[mFFC]{MIS of File Format Conversions Module}} \label{M6}  

\subsection{Module}  
File Format Conversions Module
\subsection{Uses} 
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. \\
Score Generation Module (M3): For saving generated scores as musicXML files. \\

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{SUPPORTED\_IMPORT\_FORMATS}  
    \item \texttt{SUPPORTED\_EXPORT\_FORMATS}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{3cm}|p{4cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
importFile & filePath, format & WAV & ImportError \\  
exportFile & data, format, filePath & musicXML & ExportError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  
\subsubsection{State Variables}
\begin{itemize}
    \item \textbf{None.}
\end{itemize}

\subsubsection{Environment Variables}
\begin{itemize}
    \item \textbf{fileSystemAccess:} An interface that facilitates file system operations, including reading from and writing to specified file paths.
\end{itemize}

\subsubsection{Assumptions}
\begin{enumerate}
    \item The specified file path exists and is accessible for import operations.
    \item The export destination file path is writable.
\end{enumerate}

\subsubsection{Access Routine Semantics}

\noindent \textbf{\texttt{importFile(filePath, format)}}: \\
\textbf{Precondition:} The provided \texttt{filePath} exists, and the \texttt{format} is supported for import operations. \\
\textbf{Output:} Returns the file data extracted from raw audio input contained in the file. \\
\textbf{Postcondition:} The imported data is correctly formatted as .WAV and available for further processing. \\
\textbf{Exception:} Throws \texttt{ImportError} if the file does not exist, is inaccessible, or if the specified \texttt{format} is invalid.

\vspace{2mm}
\noindent \textbf{\texttt{exportFile(data, format, filePath)}}: \\
\textbf{Precondition:} Valid \texttt{data} is provided, the \texttt{format} is supported for export, and the destination \texttt{filePath} is writable. \\
\textbf{Output:} Saves the provided \texttt{data} as a musicXML file at the given \texttt{filePath}. \\
\textbf{Postcondition:} The file at \texttt{filePath} is created or updated with the exported data in the specified format. \\
\textbf{Exception:} Throws \texttt{ExportError} if writing the file fails due to permission issues or other I/O errors.

\subsubsection{Local Functions}
\begin{itemize}
    \item \textbf{\texttt{convertToRawAudio(fileData, format)}}: Converts the provided \texttt{fileData} from the specified \texttt{format} into raw audio data.
    \item \textbf{\texttt{writeToFile(data, format, filePath)}}: Writes the provided \texttt{data} in the specified \texttt{format} to the given \texttt{filePath} using the \texttt{fileSystemAccess} interface.
\end{itemize}


\section{\hyperref[mARP]{MIS of Audio Recording and Playback Module}} \label{M7}  

\subsection{Module}  
Audio Recording and Playback Module  

\subsection{Uses}  
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. \\
Raw Signal Processing Module (M4): For filtered recorded audio, and noise reduction. \\
Audio Feature Extraction Module (M5): For extracting musical features from recorded audio. \\

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_AUDIO\_FORMAT}  
    \item \texttt{MAX\_RECORDING\_DURATION}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{3cm}|p{4cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
startRecording & None & None & RecordingError \\  
stopRecording & None & rawAudioData & RecordingError \\  
playAudio & audioData & None & PlaybackError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}
\begin{itemize}
    \item \textbf{isRecording:} A Boolean flag indicating whether audio recording is in progress. Domain: $\{\texttt{false}, \texttt{true}\}$.
    \item \textbf{currentAudioBuffer:} A buffer that accumulates raw audio data captured during a recording session.
\end{itemize}

\subsubsection{Environment Variables}
\begin{itemize}
    \item \textbf{microphoneAccess:} An interface for accessing and controlling the system's microphone hardware.
    \item \textbf{speakerOutput:} An interface for managing audio playback through the system's speaker.
\end{itemize}

\subsubsection{Assumptions}
\begin{enumerate}
    \item Both the microphone and speaker hardware are functional and accessible via their respective interfaces.
\end{enumerate}

\subsubsection{Access Routine Semantics}

\noindent \textbf{\texttt{startRecording()}}: \\
\textbf{Precondition:} The \texttt{microphoneAccess} interface is operational and no recording is in progress (\texttt{isRecording = false}). \\
\textbf{Transition:} Sets \texttt{isRecording} to \texttt{true} and initiates audio capture by invoking \texttt{captureMicrophoneInput()}. \\
\textbf{Postcondition:} Audio data is being accumulated in \texttt{currentAudioBuffer}. \\
\textbf{Exception:} Throws \texttt{RecordingError} if the microphone is unavailable or fails to start recording.

\vspace{2mm}
\noindent \textbf{\texttt{stopRecording()}}: \\
\textbf{Precondition:} A recording session is active (\texttt{isRecording = true}). \\
\textbf{Output:} Returns the captured audio data stored in \texttt{currentAudioBuffer} as raw data. \\
\textbf{Transition:} Sets \texttt{isRecording} to \texttt{false} to terminate the recording session. \\
\textbf{Postcondition:} The recording session is concluded, and the captured audio data is available for further processing. \\
\textbf{Exception:} Throws \texttt{RecordingError} if no recording is in progress when invoked.

\vspace{2mm}
\noindent \textbf{\texttt{playAudio(audioData)}}: \\
\textbf{Precondition:} Valid \texttt{audioData} is provided and the \texttt{speakerOutput} interface is operational. \\
\textbf{Output:} Plays the provided \texttt{audioData} through the speaker. \\
\textbf{Postcondition:} Audio playback is successfully initiated via \texttt{sendToSpeaker(audioData)}. \\
\textbf{Exception:} Throws \texttt{PlaybackError} if the playback process fails due to issues with the speaker or the audio data.

\subsubsection{Local Functions}
\begin{itemize}
    \item \textbf{\texttt{captureMicrophoneInput()}}: Captures audio input from the microphone and stores the data in \texttt{currentAudioBuffer}.
    \item \textbf{\texttt{sendToSpeaker(audioData)}}: Transmits the provided \texttt{audioData} to the speaker for playback.
\end{itemize}


\newpage

\bibliographystyle{plainnat}
\bibliography{../../../refs/References}

\newpage

\section*{Appendix --- Reflection}

\input{../../Reflection.tex}

\begin{enumerate}
  \item What went well while writing this deliverable?  \\
  
    Emily: Since a lot of the code has already been written (or at least planned out), 
    the process of identifying modules and their behaviours for this deliverable went 
    quickly and made the whole process a lot simpler.\\

    Mark: This document was helpful in creating a better understanding of the future 
    of ScoreGen at a more practical, rather than conceptual level. \\

    Ian: Splitting the work and dividing into sub teams helped speed up the process of 
    breaking down the two documents and their sections. This was good for work efficiency. 
    Communication before the deadline of this deliverable was productive and informative. \\

    Jackson: I think this deliverable was a good step to lay out all of our plans for 
    our code. This will honestly benefit us in our development of the app itself, as 
    having this to look back at will benefit us greatly.  \\
  
  \item What pain points did you experience during this deliverable, and how
  did you resolve them? \\

    Emily: Making the traceability matrix between modules and anticipated changes proved
    to be a bit of a challenge. We were directed to identify anticipated changes that ideally 
    affect only a single module, which forced me to think more critically about each AC and 
    why they are needed. \\

    Mark: As some modules are in the process of completion it was difficult to define specific 
    terms that hadn’t yet been implemented, thus completing the documentation required a lot of 
    communication and assumptions. It is also highly likely that changes will need to be made in 
    future revisions of this document to align with design choices that occur later during 
    implementation. \\

    Ian:  One pain point was deciding how abstract some of the descriptions of the module 
    secrets/services in the module guide. A balance had to be struck between being able to 
    adequately describe something vs explaining too many details/choices. This was easily solved 
    by re-reading the MG template, and by taking a look at previous students’ work and how 
    they handle this. \\

    Jackson: This deliverable was due very soon after the winter break, and getting back into 
    the flow of school plus reconnecting with the group and getting everyone on the same page 
    was tough. Additionally, breaking down the modules into their specifics proved tough, as 
    creating detailed information about our implementation at this stage. At the same time, 
    the app is still being developed, which was difficult to do. \\

    
  \item Which of your design decisions stemmed from speaking to your client(s)
  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
  were not, why, and where did they come from? \\

    The majority of design decisions made up until this point did not stem from speaking to clients. 
    The main decisions made such as the algorithmic choices and which file formats to support were 
    decisions made based on the team’s knowledge of signals and systems and human-computer interfacing. 
    These decisions included selecting the Fast Fourier Transform for pitch detection due to its 
    performance and efficiency and supporting widely used file formats for distribution purposes (PDF) 
    and musical representation (musicXML). \\

  \item While creating the design doc, what parts of your other documents (e.g.
  requirements, hazard analysis, etc), if any, needed to be changed, and why? \\

    N/A \\

  \item What are the limitations of your solution? Put another way, given
  unlimited resources, what could you do to make the project better? (LO\_ProbSolutions) \\

    Our project aims to create as strong an ability as possible for non-technical musicians to create 
    highly detailed notation, but there are intricacies that are extremely difficult to extract from 
    audio alone. Features like staccato, crescendo, chords, grace notes, or tempo changes are difficult 
    to differentiate from variance that occurs from regular human playing. Tackling this issue effectively 
    would probably best be done with very advanced signal processing and personally trained, or fine-tuned 
    machine learning models. Given more time, it would also be helpful to implement advanced options for 
    users to maximise precision. If for example there is a music piece with lower confidence sections, such 
    an area where there is a similar likelihood of a note being a fast-played 16th note, or a grace note, 
    it could be possible for the user to toggle through most likely interpretations with playback to determine 
    the ideal representation of their playing. \\

  \item Give a brief overview of other design solutions you considered. What
  are the benefits and tradeoffs of those other designs compared with the chosen
  design?  From all the potential options, why did you select the documented design?
  (LO\_Explores) \\

    We considered several design solutions, including purely rule-based algorithms and advanced signal processing 
    techniques. The rule-based approach would have been easier to implement but lacks the flexibility to interpret 
    complex musical nuances like dynamics and articulation. Advanced signal processing, while more capable of handling 
    these intricacies, would require more computational resources and expertise in the field. After weighing the 
    tradeoffs, we chose a hybrid approach that combines signal processing with rule-based methods. This design provides 
    a balance between accuracy, flexibility, and resource efficiency, ensuring a strong foundation for transcription 
    while leaving room for future refinement.

\end{enumerate}

\end{document}